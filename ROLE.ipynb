{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# aims\n",
    "* across group same role vs. same group across role vs. (null) across group across role\n",
    "* 리콜해내는 이벤트는 둘 중 어떤 상황에서 더 유사할까?\n",
    "* quantify1: event 간 similarity (content level)\n",
    "* quantify2: across group role\n",
    "\n",
    "1. 일단 각 그룹별 벌어졌던 이벤트를 쪼갬 (모든 그룹 sharedeb 준비)\n",
    "2. Day1 각 이벤트의 content level vector를 구함 (only nv, USE 사용) -----quantify1\n",
    "    1. USE 성능확인을 해봐야 함: 각 문장*을 넣고 pairwise vector similarity를 구하여 그것이 육안으로 확인한 내용적 유사성에 부합하는지\n",
    "    2. *각 문장: raw, exclude stopwords, only nv 이렇게 세 단계로 테스트\n",
    "3. 각 그룹의 각 이벤트에서 leader role(leader idx 1~3)을 정의하는 방법 구현(speaker와 NB_SBJ 등 구문분석 사용) -----quantify2\n",
    "4. Day1에 대한 Day2의 리콜 태깅을 불러옴\n",
    "5. 일단 각 그룹에서 전체 day1 이벤트들 대비 리콜된 이벤트들의 벡터 similarity에 특이점이 있는지 확인, across group 특이점이 있는지 확인 -----within group vector similarity가 월등히 높지 않을까 하는 걱정에서 비롯\n",
    "6. (same group across role) 리콜된 day2의 이벤트들의 day1 벡터들의 similarity 계산 -----pairwise로 전부?\n",
    "7. (across group same role) 리콜된 day2의 이벤트들의 day1 벡터들의 similarity 계산 -----pairwise로 전부; 위와 동일하게\n",
    "8. (across group across role) 리콜된 day2의 이벤트들의 day1 벡터들의 similarity 계산 -----pairwise로 전부; null로 사용"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from scipy.spatial import distance\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\"]\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "def embed(input):\n",
    "    return model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = '/home/jiunchoi/OFD/OFD_BHV_clean'\n",
    "group = 5\n",
    "sub = 1\n",
    "groupsub = '0'+str(group)+'0'+str(sub)\n",
    "\n",
    "names = []\n",
    "with open(f\"{DATADIR}/subnames\", \"r\") as f:\n",
    "    names.extend(f.read().split('\\n'))\n",
    "\n",
    "subname = names[group-1].split()\n",
    "subname = subname[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transcript = pd.read_excel(f'{DATADIR}/group-0{str(group)}/group-0{str(group)} sharedeb.xlsx')\n",
    "data_script = data_transcript['sentence']\n",
    "sharedeb = np.array(data_transcript['sharedeb'])\n",
    "sentence_embedding = np.array(embed(data_script))\n",
    "\n",
    "event_semantic_vectors = np.zeros((int(sharedeb[-1]),sentence_embedding.shape[-1]))\n",
    "for i in range (1,int(sharedeb[-1])+1):\n",
    "    event_semantic_vectors[i-1] = np.mean(sentence_embedding[sharedeb==i,:],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(193, 512)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save(f'{DATADIR}/group-0{str(group)}/group-0{str(group)} event_semantic_vectors.npy',event_semantic_vectors)\n",
    "event_semantic_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 40,\n",
       " 44,\n",
       " 45,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 83,\n",
       " 84,\n",
       " 88,\n",
       " 90,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 111,\n",
       " 118,\n",
       " 119]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group=2\n",
    "keys = [f'sub-0{group}01',f'sub-0{group}02',f'sub-0{group}03']\n",
    "\n",
    "data_transcript = pd.read_excel(f'{DATADIR}/group-0{str(group)}/group-0{str(group)} sharedeb.xlsx')\n",
    "sharedeb = np.array(data_transcript['sharedeb'])\n",
    "data_recs = np.array(data_transcript[keys])\n",
    "notrecalled_evidx=[]\n",
    "\n",
    "for i in range(len(sharedeb)):\n",
    "    count=0\n",
    "    for j in range(3):\n",
    "        if type(data_recs[i,j])!=str and np.isnan(data_recs[i,j])==True:\n",
    "            count+=1\n",
    "    if count==3:\n",
    "        if sharedeb[i] not in notrecalled_evidx:\n",
    "            notrecalled_evidx.append(sharedeb[i])\n",
    "\n",
    "recalled_evidx=[]\n",
    "\n",
    "for i in range(len(sharedeb)):\n",
    "    count=0\n",
    "    for j in range(3):\n",
    "        if type(data_recs[i,j])==str or np.isnan(data_recs[i,j])==False:\n",
    "            count+=1\n",
    "    if count==3:\n",
    "        if sharedeb[i] not in recalled_evidx:\n",
    "            recalled_evidx.append(sharedeb[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
